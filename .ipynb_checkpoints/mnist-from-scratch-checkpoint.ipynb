{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, struct, array\n",
    "\n",
    "\n",
    "def load_mnist(dataset='training', path='.', digits=np.arange(10)):\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = array.array(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = array.array(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [k for k in range(size) if lbl[k] in digits]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = np.zeros((N, rows, cols), dtype=np.uint8)\n",
    "    labels = np.zeros((N, 1), dtype=np.int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = np.array(img[ind[i] * rows * cols: (ind[i] + 1) * rows * cols]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def one_hot(i):\n",
    "    return np.eye(10)[i]\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "# derivada de la funcion sigmoid\n",
    "def derivSigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "# read the data\n",
    "images, labels = load_mnist(\"training\", path='data/mnist/')\n",
    "\n",
    "# parameters\n",
    "batch_size = 10\n",
    "np.random.seed(1)\n",
    "perceptronsHidden = 100\n",
    "epochs = 200\n",
    "\n",
    "\n",
    "# initialization\n",
    "\n",
    "Wxh = 2 * np.random.random((784, perceptronsHidden)) - 1\n",
    "Why = 2 * np.random.random((perceptronsHidden, 10)) - 1\n",
    "\n",
    "# create batches for training\n",
    "for batch in xrange(len(images) / batch_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(batch * batch_size, (batch + 1) * batch_size):\n",
    "        # input: data de entrenamiento. dim: batch_size * 784\n",
    "        X.append(images[i].flatten())\n",
    "        # expected output: batch_size * 10\n",
    "        Y.append(one_hot(labels[i][0]))\n",
    "\n",
    "    # layers:\n",
    "    l0 = np.array(X)\n",
    "    l1 = sigmoid(np.dot(l0, Wxh))\n",
    "    l2 = sigmoid(np.dot(l1, Why))\n",
    "\n",
    "    # lsoft = softmax(np.dot(l2, ))\n",
    "\n",
    "    normalized_l2 = np.array([softmax(layer2) for layer2 in l2])\n",
    "\n",
    "    # todo: apply a better error understaing, like cross-entropy\n",
    "    output_error = Y - normalized_l2\n",
    "\n",
    "    #Cross Entropy:\n",
    "    #C = -1/batch_size * (Y * np.log(normalized_l2) + (1 - Y) * np.log(1 - normalized_l2))\n",
    "\n",
    "    C = - np.array(Y) * np.log(normalized_l2)\n",
    "    print np.array(C[0])\n",
    "    stop = raw_input()\n",
    "    # gradient descent\n",
    "    l2_delta = output_error * derivSigmoid(normalized_l2)\n",
    "    hidden_error = l2_delta.dot(Why.T)\n",
    "    l1_delta = hidden_error * derivSigmoid(l1)\n",
    "\n",
    "    # weight adjustment\n",
    "    Why += l1.T.dot(l2_delta)\n",
    "    Wxh += l0.T.dot(l1_delta)\n",
    "\n",
    "    print \"error: \" + str(np.mean(np.abs(output_error)))\n",
    "\n",
    "# add the testing dataset for validation and calculate error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
