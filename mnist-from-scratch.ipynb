{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, struct, array\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image  # Esto es para desplegar imágenes en la libreta\n",
    "\n",
    "\n",
    "def load_mnist(dataset='training', path='.', digits=np.arange(10)):\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = array.array(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = array.array(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [k for k in range(size) if lbl[k] in digits]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = np.zeros((N, rows, cols), dtype=np.uint8)\n",
    "    labels = np.zeros((N, 1), dtype=np.int8)\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = np.array(img[ind[i] * rows * cols: (ind[i] + 1) * rows * cols]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# read the data\n",
    "images, labels = load_mnist(\"training\", path='data/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "x = np.array(images)\n",
    "\n",
    "plt.imshow(x[1], cmap=plt.gray())\n",
    "plt.axis('on')\n",
    "# plt.show()\n",
    "\n",
    "print x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(8, 8)\n",
      "(204, 204)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8a3a6dc8f0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimagen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# plt.imshow(imagen, cmap=plt.gray())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "# indices = np.arange(x.shape[0])\n",
    "# np.random.shuffle(indices)\n",
    "# ind = indices[0:64].reshape(8,8)\n",
    "\n",
    "# print x[ind[0, 1]].shape\n",
    "\n",
    "# print ind.shape\n",
    "\n",
    "# imagen = np.ones((10 * 16 + 4*11, 10 * 16 + 4*11))\n",
    "# print imagen.shape\n",
    "# for i in range(10):\n",
    "#     for j in range(10):\n",
    "#         imagen[4 + i * 20: 20 + i * 20, 4 + j * 20: 20 + j * 20] = x[ind[i, j], :].reshape(16,16)\n",
    "        \n",
    "# plt.imshow(imagen, cmap=plt.gray())\n",
    "# plt.axis('off')\n",
    "# plt.title(u\"Ejemplos aleatorios de imágenes a clasificar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 10\n",
    "np.random.seed(1)\n",
    "perceptronsHidden = 100\n",
    "epochs = 2000\n",
    "learning_rate = 0.02\n",
    "\n",
    "def one_hot(i):\n",
    "    return np.eye(10)[i]\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x, index):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "# derivada de la funcion sigmoid\n",
    "def derivSigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# initialization\n",
    "\n",
    "Wxh = 2 * np.random.random((784, perceptronsHidden)) - 1\n",
    "Whs = 2 * np.random.random((perceptronsHidden, 10)) - 1\n",
    "Wsy = 2 * np.random.random((10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create batches for training\n",
    "for batch in xrange(len(images) / batch_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(batch * batch_size, (batch + 1) * batch_size):\n",
    "        # input: data de entrenamiento. dim: batch_size * 784\n",
    "        X.append(images[i].flatten())\n",
    "        # expected output: batch_size * 10\n",
    "        Y.append(one_hot(labels[i][0]))\n",
    "\n",
    "    # layers:\n",
    "    l0 = np.array(X)\n",
    "    l1 = sigmoid(np.dot(l0, Wxh))\n",
    "    l2 = sigmoid(np.dot(l1, Whs))\n",
    "\n",
    "    lsoft = softmax(np.dot(l2, Wsy))\n",
    "\n",
    "    normalized_l2 = np.array([softmax(layer2) for layer2 in l2])\n",
    "    # print \"Softmax output size: \" + `normalized_l2.shape`\n",
    "    # todo: apply a better error understaing, like cross-entropy\n",
    "    output_error = Y - normalized_l2\n",
    "\n",
    "    #Cross Entropy:\n",
    "    #C = -1/batch_size * (Y * np.log(normalized_l2) + (1 - Y) * np.log(1 - normalized_l2))\n",
    "    C = (- np.array(Y) * np.log(normalized_l2)).mean()\n",
    "    # print \"Cross Entropy: \" + `C`\n",
    "    # stop = raw_input()\n",
    "    # gradient descent\n",
    "    l2_delta =  C * derivSigmoid(normalized_l2)\n",
    "    hidden_error = l2_delta.dot(Whs.T)\n",
    "    l1_delta = hidden_error * derivSigmoid(l1)\n",
    "\n",
    "    # weight adjustment\n",
    "    Whs += learning_rate * l1.T.dot(l2_delta)\n",
    "    Wxh += learning_rate * l0.T.dot(l1_delta)\n",
    "\n",
    "    print \"error: \" + str(np.mean(np.abs(output_error)))\n",
    "\n",
    "# add the testing dataset for validation and calculate error.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
